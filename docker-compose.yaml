name: nightmare

services:
  hexstrike:
    image: hexstrike:latest
    container_name: hexstrike
    build:
      context: ./kali
      dockerfile: Dockerfile
    cap_add:
      - NET_ADMIN
      - NET_RAW
    ports:
      - "6901:22"
      - "6902:8000"
    networks:
      - nightmare_network
    volumes:
      - ./vault:/root/vault:z
    environment:
      - ROOT_PASSWORD=$ROOT_PASSWORD
    stdin_open: true
    tty: true
    restart: no

  nightmare:
    image: ollama/ollama:latest
    container_name: nightmare
    ports:
      - "11435:11434"
    networks:
      - nightmare_network
    volumes:
      - nightmare_data:/root/.ollama
      - ./Modelfile:/Modelfile:ro
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: all
    #           capabilities: [gpu]
    restart: unless-stopped
    entrypoint: ["/bin/bash", "-c", "\
      ollama serve & \
      sleep 5 && \
      ollama pull ${MODEL} && \
      wait"]

  n8n:
    image: docker.n8n.io/n8nio/n8n
    container_name: n8n
    depends_on:
      - hexstrike
      - nightmare
    ports:
      - "5678:5678"
    networks:
      - nightmare_network
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - n8n_data:/home/node/.n8n
    environment:
      - GENERIC_TIMEZONE=${TIMEZONE}
      - TZ=${TIMEZONE}
      - N8N_ENFORCE_SETTINGS_FILE_PERMISSIONS=true
      - N8N_RUNNERS_ENABLED=true
      - N8N_COMMUNITY_PACKAGES_ALLOW_TOOL_USAGE=true
      - N8N_SECURE_COOKIE=false
      - NODE_ENV=production
    restart: unless-stopped

  # open-webui:
  #   image: ghcr.io/open-webui/open-webui:main
  #   container_name: open-webui
  #   depends_on:
  #     - n8n
  #   ports:
  #     - "6903:6903"
  #   networks:
  #     - nightmare_network
  #   volumes:
  #     - owui_data:/app/backend/data
  #   environment:
  #     - PORT=6903
  #     - MODEL_DOWNLOAD_DIR=/models
  #     - OLLAMA_API_BASE_URL=http://nightmare:11435
  #     - LOG_LEVEL=debug
  #   # extra_hosts:
  #   #   - "host.docker.internal:host-gateway"
  #   restart: unless-stopped

  # ollama-telegram:
  #   image: ruecat/ollama-telegram
  #   depends_on:
  #     - kali-hexstrike
  #   environment:
  #     - TOKEN=$TELEGRAM_BOT_TOKEN
  #     - ADMIN_IDS=$TELEGRAM_USER_ID
  #     - USER_IDS=$TELEGRAM_USER_ID
  #     - INITMODEL=$OLLAMA_MODEL
  #     - OLLAMA_BASE_URL=host.docker.internal
  #     - OLLAMA_PORT=11434
  #     - TIMEOUT=43200
  #   extra_hosts:
  #     - "host.docker.internal:host-gateway"
  #   restart: on-failure

volumes:
  nightmare_data:
  n8n_data:
  # owui_data:

networks:
  nightmare_network:
    driver: bridge